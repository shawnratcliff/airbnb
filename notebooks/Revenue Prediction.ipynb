{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from django.db.models import F, ExpressionWrapper, Expression, DurationField\n",
    "from django.contrib.gis.db.models.functions import AsGeoJSON\n",
    "from ast import literal_eval\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpack 1D vector series into columns\n",
    "def unpack_vectors(vector_series):\n",
    "    VECTOR_LENGTH = 300\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(VECTOR_LENGTH):\n",
    "        new_df['description_vec_%d' % i] = vector_series.apply(lambda x: x[i])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Census tract-level data\n",
    "TRACT_DATA = pickle.load(open('../pickles/census_data_ml.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 57)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-saved extracted listing data\n",
    "listing_df = pickle.load(open('../pickles/listings_dataframe.p', 'rb'))\n",
    "extra_listing_data_df = pickle.load(open('../pickles/listings_extra_df.p', 'rb'))\n",
    "# listing_topic_df = pickle.load(open('../pickles/listing_topic_df.p', 'rb'))\n",
    "\n",
    "# Merge the listing data into one frame\n",
    "listing_df = pd.merge(listing_df, extra_listing_data_df, on='id', how='left')\n",
    "\n",
    "# Drop the description-related stuff (no text features)\n",
    "listing_df.drop(['description', 'description_vec'], axis=1, inplace=True)\n",
    "\n",
    "# Unpack the doc vectors and add back into dataframe; then drop the vector column\n",
    "# unpacked = unpack_vectors(listing_df.description_vec)\n",
    "# listing_df[unpacked.columns] = unpacked\n",
    "# listing_df.drop('description_vec', axis=1, inplace=True)\n",
    "\n",
    "# Let's drop some more columns to see if we need them or not\n",
    "drop_cols = ['review_scores_rating', 'review_scores_accuracy',\n",
    "             'review_scores_cleanliness', 'review_scores_checkin',\n",
    "             'review_scores_communication', 'review_scores_location',\n",
    "             'review_scores_value', 'require_guest_phone_verification',\n",
    "             'require_guest_profile_picture', 'instant_bookable',\n",
    "             'host_is_superhost', 'host_identity_verified',\n",
    "             'is_english', 'guests_included', 'extra_people',\n",
    "             'estimated_revenue_per_month', 'reviews_per_month',\n",
    "             'block_group_id', 'zipcode_id', 'neighborhood_id',\n",
    "            ]\n",
    "listing_df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# listing_df = pd.merge(listing_df, listing_topic_df, on='id', how='left')\n",
    "listing_df.shape # Should be 26048 length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add census tract-level data, but only certain features\n",
    "percent_vars = [c for c in TRACT_DATA.columns if c.startswith('percent_')]\n",
    "census_vars = [col for col in TRACT_DATA.columns\n",
    "               if col in ('tract_id', 'B25064_001E', 'B19301_001E', 'B01003_001E', 'B25001_001E')\n",
    "               or col in percent_vars]\n",
    "\n",
    "tract_df = TRACT_DATA[census_vars].copy()\n",
    "\n",
    "# Fill in missing percent columns with 0\n",
    "percent_cols = [c for c in TRACT_DATA.columns if c.startswith('percent_')]\n",
    "tract_df[percent_cols] = tract_df[percent_cols].fillna(value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12994, 72)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the tables \n",
    "merged=pd.merge(listing_df, tract_df, on='tract_id', how='left')\n",
    "\n",
    "# Drop rows with null values \n",
    "merged.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Drop price outliers: massive boost in model accuracy\n",
    "merged = merged[merged.price <= 1000]\n",
    "\n",
    "# Drop listings with no reviews: prices haven't been\n",
    "# validated by the market\n",
    "merged = merged[merged.review_count >= 5]\n",
    "\n",
    "# Now, drop review count from the table\n",
    "merged.drop(['review_count'], axis=1, inplace=True)\n",
    "\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build id, row index lookup table (so that we can later derive\n",
    "# the listing ids from the row index in X (which contains no id))\n",
    "id_to_index_df = pd.DataFrame(list(zip(merged.id, merged.index)), columns=['id', 'X_index'])\n",
    "\n",
    "# Build feature and target vectors\n",
    "X = merged.drop(['id', 'tract_id', 'price'], axis=1).copy()\n",
    "y = merged.price.copy()\n",
    "\n",
    "# Convert numeric types to floats\n",
    "category_cols = ['room_type', 'property_type', 'bed_type', 'cancellation_policy']\n",
    "float_cols = [col for col in list(X.columns) if col not in category_cols]\n",
    "X[float_cols] = X[float_cols].astype(np.float64)\n",
    "\n",
    "# Fit LabelEncoders to transform training and future prediction data\n",
    "room_type_le = preprocessing.LabelEncoder().fit(X.room_type)\n",
    "property_type_le = preprocessing.LabelEncoder().fit(X.property_type)\n",
    "bed_type_le = preprocessing.LabelEncoder().fit(X.bed_type)\n",
    "cancellation_policy_le = preprocessing.LabelEncoder().fit(X.cancellation_policy)\n",
    "\n",
    "# Replace categorical columns with LabelEncoder transformed values\n",
    "X['room_type'] = room_type_le.transform(X.room_type)\n",
    "X['property_type'] = property_type_le.transform(X.property_type)\n",
    "X['bed_type'] = bed_type_le.transform(X.bed_type)\n",
    "X['cancellation_policy'] = cancellation_policy_le.transform(X.cancellation_policy)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.837915183871\n",
      "Test score: 0.743824416441\n",
      "median absolute error:  18.4781344415\n",
      "mean absolute error:  33.9354927161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import median_absolute_error, mean_absolute_error\n",
    "\n",
    "# Train\n",
    "model=RandomForestRegressor(n_estimators=15, max_features=None, min_samples_leaf=8, n_jobs=-1, \n",
    "                            verbose=1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Train score: %s' % model.score(X_train, y_train))\n",
    "print('Test score: %s' % model.score(X_test, y_test))\n",
    "\n",
    "# Predict/evaluate\n",
    "y_predict = model.predict(X_test)\n",
    "print('median absolute error: ', median_absolute_error(y_test, y_predict))\n",
    "print('mean absolute error: ', mean_absolute_error(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model on the whole data, and pickle it\n",
    "# model.fit(X, y)\n",
    "# model_with_extras = {\n",
    "#     'model': model,\n",
    "#     'room_type_le': room_type_le,\n",
    "#     'property_type_le': property_type_le,\n",
    "#     'bed_type_le': bed_type_le,\n",
    "#     'cancellation_policy_le': cancellation_policy_le\n",
    "# }\n",
    "\n",
    "# pickle.dump(model_with_extras, open('../pickles/price_model_with_extras.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182, 127\n",
      "27, 24\n",
      "53, 65\n",
      "263, 199\n",
      "157, 199\n",
      "106, 99\n",
      "99, 100\n",
      "81, 65\n",
      "271, 395\n",
      "100, 130\n",
      "70, 70\n",
      "184, 269\n",
      "108, 80\n",
      "122, 70\n",
      "131, 195\n",
      "98, 65\n",
      "460, 249\n",
      "147, 139\n",
      "75, 59\n",
      "176, 165\n"
     ]
    }
   ],
   "source": [
    "# Take a look at some predictions vs. actual values\n",
    "\n",
    "for i in range(3,1000)[::50]:\n",
    "    predict = y_predict[i]\n",
    "    actual = y_test.iloc[i]\n",
    "    print('%.0f,' % predict, '%.0f' % actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       variable   importance\n",
      "45                     bedrooms       0.5301\n",
      "43                    bathrooms     0.119503\n",
      "51                    room_type    0.0590341\n",
      "54                  B19301_001E    0.0490322\n",
      "63  percent_bachelors_or_higher    0.0284418\n",
      "48                    longitude    0.0196936\n",
      "42             availability_365    0.0187893\n",
      "67         percent_homes_vacant    0.0172215\n",
      "0                  accommodates    0.0157679\n",
      "58  percent_professional_degree    0.0141055\n",
      "56                  B25064_001E    0.0127064\n",
      "47                     latitude    0.0117314\n",
      "64            percent_age_18_34   0.00764658\n",
      "46         host_experience_days   0.00725235\n",
      "57             percent_age_0_17   0.00680311\n",
      "61      percent_doctoral_degree   0.00651873\n",
      "59       percent_masters_degree    0.0064684\n",
      "65     percent_bachelors_degree   0.00631671\n",
      "3                    amenity_11   0.00517562\n",
      "53                  B01003_001E   0.00502131\n",
      "62            percent_age_65_up   0.00490082\n",
      "50                property_type   0.00489284\n",
      "66     percent_associate_degree   0.00449194\n",
      "60            percent_age_50_64   0.00431343\n",
      "23                   amenity_30   0.00392322\n",
      "55                  B25001_001E    0.0037694\n",
      "68            percent_age_35_49    0.0031909\n",
      "24                   amenity_31   0.00276808\n",
      "38                    amenity_6   0.00214466\n",
      "49               minimum_nights   0.00190404\n",
      "8                    amenity_16   0.00159338\n",
      "27                   amenity_35   0.00145986\n",
      "12                    amenity_2   0.00130405\n",
      "33                   amenity_40   0.00107653\n",
      "15                   amenity_22  0.000950249\n",
      "37                    amenity_5  0.000882878\n",
      "7                    amenity_15  0.000803338\n",
      "16                   amenity_23   0.00078392\n",
      "13                   amenity_20  0.000695282\n",
      "52          cancellation_policy  0.000580773\n",
      "17                   amenity_24  0.000565325\n",
      "25                   amenity_32   0.00056481\n",
      "10                   amenity_18  0.000506637\n",
      "14                   amenity_21  0.000476676\n",
      "20                   amenity_28  0.000423347\n",
      "22                    amenity_3  0.000413684\n",
      "40                    amenity_8  0.000392777\n",
      "11                   amenity_19   0.00038007\n",
      "5                    amenity_13  0.000367905\n",
      "29                   amenity_37  0.000334169\n",
      "1                     amenity_1   0.00029887\n",
      "2                    amenity_10  0.000275973\n",
      "34                   amenity_41  0.000273891\n",
      "4                    amenity_12  0.000228227\n",
      "39                    amenity_7  0.000213995\n",
      "18                   amenity_26  0.000114524\n",
      "31                   amenity_39  8.40987e-05\n",
      "9                    amenity_17  8.17774e-05\n",
      "6                    amenity_14  6.62881e-05\n",
      "19                   amenity_27  6.49872e-05\n",
      "21                   amenity_29  3.92045e-05\n",
      "41                    amenity_9  3.54013e-05\n",
      "26                   amenity_33  1.54718e-05\n",
      "28                   amenity_36  1.53488e-05\n",
      "30                   amenity_38   6.8565e-06\n",
      "44                     bed_type  9.68571e-07\n",
      "36                   amenity_44            0\n",
      "35                   amenity_42            0\n",
      "32                    amenity_4            0\n"
     ]
    }
   ],
   "source": [
    "# Show which features were important to the model\n",
    "feat_imp = pd.DataFrame([X.columns, model.feature_importances_]).transpose()\n",
    "feat_imp.columns = ['variable', 'importance']\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(feat_imp.sort_values('importance', ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predict</th>\n",
       "      <th>err</th>\n",
       "      <th>abs_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5198.000000</td>\n",
       "      <td>5198.000000</td>\n",
       "      <td>5198.000000</td>\n",
       "      <td>5198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>142.996730</td>\n",
       "      <td>142.131821</td>\n",
       "      <td>-0.864908</td>\n",
       "      <td>33.935493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.388853</td>\n",
       "      <td>98.462611</td>\n",
       "      <td>60.927223</td>\n",
       "      <td>50.606674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.308678</td>\n",
       "      <td>-634.423019</td>\n",
       "      <td>0.012946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.586329</td>\n",
       "      <td>-14.581719</td>\n",
       "      <td>8.299550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>113.945244</td>\n",
       "      <td>4.013777</td>\n",
       "      <td>18.478134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>168.750000</td>\n",
       "      <td>167.709842</td>\n",
       "      <td>21.694512</td>\n",
       "      <td>38.203975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>720.202446</td>\n",
       "      <td>369.132274</td>\n",
       "      <td>634.423019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actual      predict          err      abs_err\n",
       "count  5198.000000  5198.000000  5198.000000  5198.000000\n",
       "mean    142.996730   142.131821    -0.864908    33.935493\n",
       "std     120.388853    98.462611    60.927223    50.606674\n",
       "min      19.000000    23.308678  -634.423019     0.012946\n",
       "25%      75.000000    78.586329   -14.581719     8.299550\n",
       "50%     108.000000   113.945244     4.013777    18.478134\n",
       "75%     168.750000   167.709842    21.694512    38.203975\n",
       "max    1000.000000   720.202446   369.132274   634.423019"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare test vs. predicted\n",
    "compare = pd.DataFrame([list(y_test), list(y_predict)]).transpose()\n",
    "compare.columns = ['actual', 'predict']\n",
    "compare['err'] = compare.predict - compare.actual\n",
    "compare['abs_err'] = compare.err.apply(lambda x: abs(x))\n",
    "compare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find similar listings\n",
    "weights = model.feature_importances_\n",
    "key = X_test.iloc[78]\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "X_scaled = pd.DataFrame(robust_scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "key = pd.Series(robust_scaler.transform(key.values.reshape(1,-1))[0], index=key.index)\n",
    "\n",
    "def get_similar_listings(key, top_n=5):\n",
    "    diffs = (X_scaled * weights) - (key * weights)\n",
    "    dists = pd.DataFrame(np.sum(np.square(diffs), axis=1), columns=['distance'], index=X_scaled.index)\n",
    "    index_vals = dists.sort_values('distance').index[:top_n]\n",
    "    return [listing_lookup_df.get_value(idx, 'id') for idx in index_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HISTORIC LUXE VENICE CARRIAGE HOUSE ($189) (Venice) https://www.airbnb.com/rooms/1661684\n",
      "Venice Cottage 3 Blocks to Beach ($135) (Venice) https://www.airbnb.com/rooms/1159836\n",
      "BRIGHT ONE BEDROOM IN PRIME VENICE! ($195) (Venice) https://www.airbnb.com/rooms/11223716\n",
      "Venice Beach/Abbot Kinney Hideaway ($129) (Venice) https://www.airbnb.com/rooms/5879466\n",
      "Modern Oasis w/Outdoor Patio, BBQ & Chef's Kitchen ($99) (Venice) https://www.airbnb.com/rooms/3011569\n"
     ]
    }
   ],
   "source": [
    "for listing_id in get_similar_listings(key):\n",
    "    listing = Listing.objects.get(pk=listing_id)\n",
    "    text = '%s ($%.0f) (%s)' % (listing.name, listing.price, listing.neighborhood.name)\n",
    "    url = 'https://www.airbnb.com/rooms/%d' % listing.id\n",
    "    print(text, url)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar_listings = {\n",
    "    'scaler': robust_scaler,\n",
    "    'listing_lookup_df': listing_lookup_df,\n",
    "    'all_listings_scaled': X_scaled,\n",
    "    'weights': weights,\n",
    "}\n",
    "pickle.dump(similar_listings, open('../pickles/similar_listings.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
